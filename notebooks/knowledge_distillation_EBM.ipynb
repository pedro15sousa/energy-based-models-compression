{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Google Colab. Assuming local environment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the notebook is running on Colab\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    # This block will run only in Google Colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab. Cloning the repository.\")\n",
    "    !git clone https://github.com/pedro15sousa/energy-based-models-compression.git\n",
    "    %cd energy-based-models-compression/notebooks\n",
    "else: \n",
    "    # This block will run if not in Google Colab\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running on Google Colab. Assuming local environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # This adds the parent directory (main_folder) to the Python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pl/gjvtfzbj4691nr_0pszjdspw0000gn/T/ipykernel_25737/3617302433.py:37: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "Seed set to 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Device:  cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.utils.data as data\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install --quiet pytorch-lightning\n",
    "    import pytorch_lightning as pl\n",
    "# Callbacks\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "# Pytorch Summary\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "except ModuleNotFoundError:\n",
    "    !pip install --quiet torchsummary\n",
    "    from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "from metrics.classifier import VGG\n",
    "from metrics.scores import frechet_inception_distance, inception_score\n",
    "from EBM import DeepEnergyModel\n",
    "from energy_funcs.cnn import CNNModel\n",
    "from energy_funcs.resnet import ResNet18\n",
    "from sampler import Sampler\n",
    "from callbacks import InceptionScoreCallback, \\\n",
    "    FIDCallback, SamplerCallback, OutlierCallback, \\\n",
    "    GenerateImagesCallback\n",
    "\n",
    "import shutil\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../saved_models\"\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "pl.seed_everything(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations applied on each image => make them a tensor and normalize between -1 and 1\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                               ])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_set = MNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "\n",
    "# Loading the test set\n",
    "test_set = MNIST(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "# Note that for actually training a model, we will use different data loaders\n",
    "# with a lower batch size.\n",
    "train_loader = data.DataLoader(train_set, batch_size=64, shuffle=True,  drop_last=True,  num_workers=2, pin_memory=True)\n",
    "test_loader  = data.DataLoader(test_set,  batch_size=128, shuffle=False, drop_last=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists and loaded.\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 28, 28]           1,280\n",
      "              ReLU-2          [-1, 128, 28, 28]               0\n",
      "            Conv2d-3          [-1, 128, 28, 28]         147,584\n",
      "              ReLU-4          [-1, 128, 28, 28]               0\n",
      "            Conv2d-5          [-1, 128, 28, 28]         147,584\n",
      "              ReLU-6          [-1, 128, 28, 28]               0\n",
      "         MaxPool2d-7          [-1, 128, 14, 14]               0\n",
      "            Conv2d-8          [-1, 256, 14, 14]         295,168\n",
      "              ReLU-9          [-1, 256, 14, 14]               0\n",
      "           Conv2d-10          [-1, 256, 14, 14]         590,080\n",
      "             ReLU-11          [-1, 256, 14, 14]               0\n",
      "           Conv2d-12          [-1, 256, 14, 14]         590,080\n",
      "             ReLU-13          [-1, 256, 14, 14]               0\n",
      "        MaxPool2d-14            [-1, 256, 7, 7]               0\n",
      "           Linear-15                   [-1, 10]         125,450\n",
      "================================================================\n",
      "Total params: 1,897,226\n",
      "Trainable params: 1,897,226\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 7.18\n",
      "Params size (MB): 7.24\n",
      "Estimated Total Size (MB): 14.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('../saved_models/mnist-classifier-1 (1).pth'):\n",
    "    # Load the best model\n",
    "    mnist_classifier = VGG()\n",
    "\n",
    "    if device == 'cuda':\n",
    "        mnist_classifier.load_state_dict(torch.load('../saved_models/mnist-classifier-1 (1).pth'))\n",
    "    else:\n",
    "        mnist_classifier.load_state_dict(torch.load('../saved_models/mnist-classifier-1 (1).pth', map_location=torch.device('cpu')))\n",
    "\n",
    "    mnist_classifier.to(device)\n",
    "    print(\"Model already exists and loaded.\")\n",
    "    summary(mnist_classifier, input_size=(1, 28, 28))\n",
    "else:\n",
    "    print(\"Classifier not found in saved_models. Please run the classifier notebook first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 14, 14]           3,200\n",
      "             Swish-2           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-3             [-1, 64, 7, 7]               0\n",
      "            Conv2d-4             [-1, 64, 7, 7]          36,928\n",
      "             Swish-5             [-1, 64, 7, 7]               0\n",
      "            Conv2d-6             [-1, 64, 7, 7]          36,928\n",
      "             Swish-7             [-1, 64, 7, 7]               0\n",
      "BasicResidualBlock-8             [-1, 64, 7, 7]               0\n",
      "            Conv2d-9             [-1, 64, 7, 7]          36,928\n",
      "            Swish-10             [-1, 64, 7, 7]               0\n",
      "           Conv2d-11             [-1, 64, 7, 7]          36,928\n",
      "            Swish-12             [-1, 64, 7, 7]               0\n",
      "BasicResidualBlock-13             [-1, 64, 7, 7]               0\n",
      "           Conv2d-14            [-1, 128, 4, 4]          73,856\n",
      "            Swish-15            [-1, 128, 4, 4]               0\n",
      "           Conv2d-16            [-1, 128, 4, 4]         147,584\n",
      "           Conv2d-17            [-1, 128, 4, 4]           8,320\n",
      "            Swish-18            [-1, 128, 4, 4]               0\n",
      "BasicResidualBlock-19            [-1, 128, 4, 4]               0\n",
      "           Conv2d-20            [-1, 128, 4, 4]         147,584\n",
      "            Swish-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,584\n",
      "            Swish-23            [-1, 128, 4, 4]               0\n",
      "BasicResidualBlock-24            [-1, 128, 4, 4]               0\n",
      "           Conv2d-25            [-1, 256, 2, 2]         295,168\n",
      "            Swish-26            [-1, 256, 2, 2]               0\n",
      "           Conv2d-27            [-1, 256, 2, 2]         590,080\n",
      "           Conv2d-28            [-1, 256, 2, 2]          33,024\n",
      "            Swish-29            [-1, 256, 2, 2]               0\n",
      "BasicResidualBlock-30            [-1, 256, 2, 2]               0\n",
      "           Conv2d-31            [-1, 256, 2, 2]         590,080\n",
      "            Swish-32            [-1, 256, 2, 2]               0\n",
      "           Conv2d-33            [-1, 256, 2, 2]         590,080\n",
      "            Swish-34            [-1, 256, 2, 2]               0\n",
      "BasicResidualBlock-35            [-1, 256, 2, 2]               0\n",
      "           Conv2d-36            [-1, 512, 1, 1]       1,180,160\n",
      "            Swish-37            [-1, 512, 1, 1]               0\n",
      "           Conv2d-38            [-1, 512, 1, 1]       2,359,808\n",
      "           Conv2d-39            [-1, 512, 1, 1]         131,584\n",
      "            Swish-40            [-1, 512, 1, 1]               0\n",
      "BasicResidualBlock-41            [-1, 512, 1, 1]               0\n",
      "           Conv2d-42            [-1, 512, 1, 1]       2,359,808\n",
      "            Swish-43            [-1, 512, 1, 1]               0\n",
      "           Conv2d-44            [-1, 512, 1, 1]       2,359,808\n",
      "            Swish-45            [-1, 512, 1, 1]               0\n",
      "BasicResidualBlock-46            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-47            [-1, 512, 1, 1]               0\n",
      "           Linear-48                   [-1, 10]           5,130\n",
      "         ResNet18-49                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 11,170,570\n",
      "Trainable params: 11,170,570\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.76\n",
      "Params size (MB): 42.61\n",
      "Estimated Total Size (MB): 43.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretrained_filename = os.path.join(CHECKPOINT_PATH, \"MNIST_resnet18.ckpt\")\n",
    "teacher_model = DeepEnergyModel.load_from_checkpoint(pretrained_filename)\n",
    "summary(teacher_model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilledDeepEnergyModel(DeepEnergyModel):\n",
    "    def __init__(self, img_shape, batch_size, soft_loss_weight, hard_loss_weight, \n",
    "                temperature=2.0, f=CNNModel, **f_args):\n",
    "        super().__init__(img_shape=img_shape, batch_size=batch_size, f=f, **f_args)\n",
    "        self.teacher_energy = nn.Linear(10, 1).to(device)\n",
    "        self.soft_loss_weight = soft_loss_weight\n",
    "        self.hard_loss_weight = hard_loss_weight\n",
    "        self.temperature = temperature\n",
    "        self.cnn = f(**f_args).to(device)\n",
    "        self.sampler = Sampler(self.cnn, img_shape=img_shape, sample_size=batch_size)\n",
    "\n",
    "    # def set_teacher_model(self, teacher_model):\n",
    "    #     self.teacher_model = teacher_model\n",
    "    #     self.teacher_model.eval()\n",
    "\n",
    "    def get_mse_loss(self, student_output, teacher_output):\n",
    "        \"\"\"\n",
    "        Calculate the MSE loss as the KL divergence between the soft targets from the teacher\n",
    "        and the predictions of the student. The temperature T is used to soften the probability distributions.\n",
    "        \"\"\"\n",
    "        loss = F.mse_loss(student_output, teacher_output)\n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = super().training_step(batch, batch_idx)\n",
    "\n",
    "        real_imgs, _ = batch\n",
    "        fake_imgs = self.sampler.sample_new_exmps(steps=60, step_size=10)\n",
    "        # Predict energy score for all images\n",
    "        inp_imgs = torch.cat([real_imgs, fake_imgs], dim=0)\n",
    "\n",
    "        student_energy = self.cnn(inp_imgs)\n",
    "        with torch.no_grad():\n",
    "            teacher_energy = self.teacher_energy(teacher_model(inp_imgs)).squeeze()\n",
    "\n",
    "        # Calculate mse loss and add it to the original loss\n",
    "        mse_loss = self.get_mse_loss(student_energy, teacher_energy)\n",
    "        total_loss = self.hard_loss_weight*loss + self.soft_loss_weight*mse_loss\n",
    "\n",
    "        # Logging\n",
    "        self.log('distillation_loss', mse_loss)\n",
    "        self.log('total_loss', total_loss)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = super().training_step(batch, batch_idx)\n",
    "\n",
    "        real_imgs, _ = batch\n",
    "        fake_imgs = self.sampler.sample_new_exmps(steps=60, step_size=10)\n",
    "        # Predict energy score for all images\n",
    "        inp_imgs = torch.cat([real_imgs, fake_imgs], dim=0)\n",
    "\n",
    "        student_energy = self.cnn(inp_imgs)\n",
    "        with torch.no_grad():\n",
    "            teacher_energy = self.teacher_energy(teacher_model(inp_imgs))\n",
    "\n",
    "        # Calculate mse loss and add it to the original loss\n",
    "        mse_loss = self.get_mse_loss(student_energy, teacher_energy)\n",
    "        total_loss = self.hard_loss_weight*loss + self.soft_loss_weight*mse_loss\n",
    "\n",
    "        self.log('val_distillation_loss', mse_loss)\n",
    "        self.log('val_total_loss', total_loss)\n",
    "        return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scores(trainer, default_root_dir):\n",
    "    is_callback = [cb for cb in trainer.callbacks if isinstance(cb, InceptionScoreCallback)][0]\n",
    "    epoch_is_scores = is_callback.scores\n",
    "    is_path = os.path.join(default_root_dir, \"epoch_is_scores.json\")\n",
    "\n",
    "    with open(is_path, 'w') as f:\n",
    "        json.dump(epoch_is_scores, f)\n",
    "\n",
    "    fid_callback = [cb for cb in trainer.callbacks if isinstance(cb, FIDCallback)][0]\n",
    "    epoch_fid_scores = fid_callback.scores\n",
    "    fid_path = os.path.join(default_root_dir, \"epoch_fid_scores.json\")\n",
    "\n",
    "    with open(fid_path, 'w') as f:\n",
    "        json.dump(epoch_fid_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVE_PATH = \"/content/drive/My Drive/EBM_saved_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(**kwargs):\n",
    "\n",
    "    default_root_dir = os.path.join(CHECKPOINT_PATH, f\"MNIST/student\")\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(default_root_dir=default_root_dir,\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=60,\n",
    "                         gradient_clip_val=0.1,\n",
    "                         callbacks=[ModelCheckpoint(dirpath=DRIVE_PATH, filename='MNIST_resnet_student', save_top_k=-1, every_n_epochs=1),\n",
    "                                    GenerateImagesCallback(every_n_epochs=3),\n",
    "                                    SamplerCallback(every_n_epochs=3),\n",
    "                                    OutlierCallback(),\n",
    "                                    LearningRateMonitor(\"epoch\"),\n",
    "                                    InceptionScoreCallback(mnist_classifier),\n",
    "                                    FIDCallback(mnist_classifier)\n",
    "                                    ])\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"MNIST_resnet_student.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        student_model = DistilledDeepEnergyModel.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        print(\"No pretrained model found. Start training from scratch...\")\n",
    "        pl.seed_everything(42)\n",
    "        student_model = DistilledDeepEnergyModel(**kwargs)\n",
    "        student_model.to(device)\n",
    "\n",
    "    trainer.fit(student_model, train_loader, test_loader)\n",
    "\n",
    "    student_model = DeepEnergyModel.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    save_scores(trainer, default_root_dir)\n",
    "        \n",
    "    # No testing as we are more interested in other properties\n",
    "    return student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %reload_ext tensorboard\n",
    "    %tensorboard --logdir saved_models/MNIST/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 42\n",
      "\n",
      "  | Name           | Type     | Params | In sizes       | Out sizes\n",
      "-------------------------------------------------------------------------\n",
      "0 | cnn            | CNNModel | 77.0 K | [1, 1, 28, 28] | [1]      \n",
      "1 | teacher_energy | Linear   | 11     | ?              | ?        \n",
      "-------------------------------------------------------------------------\n",
      "77.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "77.0 K    Total params\n",
      "0.308     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrained model found. Start training from scratch...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db12366d22964f399df9223f80880c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedrosousa/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/pedrosousa/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/Users/pedrosousa/Documents/Cambridge/Principles of ML Systems/energy-based-models-compression/notebooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pedrosousa/Documents/Cambridge/Principles of ML Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(\u001b[39m42\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# MNIST dataset images are 28x28 pixels in size and are black and white, so only have one channel\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m student_model \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     img_shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39mtrain_loader\u001b[39m.\u001b[39mbatch_size,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                     soft_loss_weight\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                     hard_loss_weight\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n",
      "\u001b[1;32m/Users/pedrosousa/Documents/Cambridge/Principles of ML Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     student_model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(student_model, train_loader, test_loader)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m student_model \u001b[39m=\u001b[39m DeepEnergyModel\u001b[39m.\u001b[39mload_from_checkpoint(trainer\u001b[39m.\u001b[39mcheckpoint_callback\u001b[39m.\u001b[39mbest_model_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m save_scores(trainer, default_root_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrosousa/Documents/Cambridge/Principles%20of%20ML%20Systems/energy-based-models-compression/notebooks/knowledge_distillation_EBM.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# No testing as we are more interested in other properties\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1561\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[39m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1481\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1482\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1488\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[1;32m   1489\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \u001b[39m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \n\u001b[1;32m   1560\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1561\u001b[0m     loaded \u001b[39m=\u001b[39m _load_from_checkpoint(\n\u001b[1;32m   1562\u001b[0m         \u001b[39mcls\u001b[39m,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1563\u001b[0m         checkpoint_path,\n\u001b[1;32m   1564\u001b[0m         map_location,\n\u001b[1;32m   1565\u001b[0m         hparams_file,\n\u001b[1;32m   1566\u001b[0m         strict,\n\u001b[1;32m   1567\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1568\u001b[0m     )\n\u001b[1;32m   1569\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:61\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m map_location \u001b[39m=\u001b[39m map_location \u001b[39mor\u001b[39;00m _default_map_location\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 61\u001b[0m     checkpoint \u001b[39m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[39m=\u001b[39mmap_location)\n\u001b[1;32m     63\u001b[0m \u001b[39m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     64\u001b[0m checkpoint \u001b[39m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     65\u001b[0m     checkpoint, checkpoint_path\u001b[39m=\u001b[39m(checkpoint_path \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(checkpoint_path, (\u001b[39mstr\u001b[39m, Path)) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     66\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightning_fabric/utilities/cloud_io.py:55\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     51\u001b[0m         \u001b[39mstr\u001b[39m(path_or_url),\n\u001b[1;32m     52\u001b[0m         map_location\u001b[39m=\u001b[39mmap_location,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     54\u001b[0m fs \u001b[39m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 55\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39mopen(path_or_url, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mload(f, map_location\u001b[39m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fsspec/spec.py:1154\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1153\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> 1154\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_open(\n\u001b[1;32m   1155\u001b[0m         path,\n\u001b[1;32m   1156\u001b[0m         mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m   1157\u001b[0m         block_size\u001b[39m=\u001b[39mblock_size,\n\u001b[1;32m   1158\u001b[0m         autocommit\u001b[39m=\u001b[39mac,\n\u001b[1;32m   1159\u001b[0m         cache_options\u001b[39m=\u001b[39mcache_options,\n\u001b[1;32m   1160\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1161\u001b[0m     )\n\u001b[1;32m   1162\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1163\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fsspec/implementations/local.py:183\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fsspec/implementations/local.py:287\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 287\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_open()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/fsspec/implementations/local.py:292\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[1;32m    291\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[0;32m--> 292\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode)\n\u001b[1;32m    293\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[1;32m    294\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/Users/pedrosousa/Documents/Cambridge/Principles of ML Systems/energy-based-models-compression/notebooks'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# MNIST dataset images are 28x28 pixels in size and are black and white, so only have one channel\n",
    "student_model = train_model(\n",
    "                    img_shape=(1,28,28),\n",
    "                    batch_size=train_loader.batch_size,\n",
    "                    soft_loss_weight=0.5,\n",
    "                    hard_loss_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
